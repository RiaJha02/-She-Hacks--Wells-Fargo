# -*- coding: utf-8 -*-
"""SheHacks_Submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YTumTQyqYvN_bIH5VwVZ8W4I56BHKGsp

## **Importing Libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from pandas.plotting import scatter_matrix
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

import nltk
from nltk.corpus import stopwords
nltk.download('punkt')
from nltk.tokenize import word_tokenize
import string
from nltk import sent_tokenize, word_tokenize
nltk.download('stopwords')

from collections import Counter
import collections
nltk.download('averaged_perceptron_tagger')

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import metrics
from sklearn.metrics import confusion_matrix

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error 


from dateutil.parser import parse
from datetime import datetime
from scipy.stats import norm

import sklearn
from sklearn.model_selection import cross_val_predict
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_validate
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import RobustScaler

"""## **Loading Data**"""

train = pd.read_csv('wells_fargo_train.csv',sep=',',header=0)
test = pd.read_csv('wells_fargo_test.csv',sep=',',header=0)

print(train.shape)
print(test.shape)

train.columns = train.columns.str.replace(' ', '_') 
test.columns = test.columns.str.replace(' ', '_')

print(train.head(0))
print(test.head(0))

train.info()

test.info()

"""## **Visualizing Data**"""

plt.figure(figsize=(20,10))
plt.title('Unique Counts')
plt.xlabel('Id')
plt.ylabel('Unique Headcount')
plt.plot(train['Unique_Headcount'][6100:6300])
plt.show()

check = ['Gender', 'Visa_Status', 'Fiscal_Year', 'Study_Year', 'WorkTerm', 'Career']
for i in check:
  sns.countplot(y=i, data=train)

"""## **Text Cleaning and Preprocessing**"""

Stopwords = set(stopwords.words('english'))
punctuations = '''!()---[]{};,.:'"\,<>./?@#$%^&*_~''''``'"''"

def listToString(s): 
	str1 = " "
	return (str1.join(s))

train.iloc[0,:]

def clean_1(df):
  Combo = df["Term_Type"] +" "+df["Career"] + " "+df['Program_Level']+" "+df["Study_Year"]+" "+df["Faculty_Group"]+" "+df["Program_Grouping"]+" "+df["Coop_Regular"]+" "+df["WorkTerm"]+" "+df["Attendance"]+" "+df["Visa_Status"]+" "+df["Gender"]
  Combo={'Combo':Combo}
  df2 = pd.DataFrame(Combo)
  stop_words = set(stopwords.words('english')) 
  for i in range(len(df2)) : 
    df2.loc[i,'Combo']=nltk.word_tokenize((df2.loc[i, 'Combo'])) 
    text=df2.loc[i, 'Combo']
    filtered_sentence = [] 
    for w in text: 
	    if w not in stop_words and w not in punctuations: 
		    filtered_sentence.append(w) 
    df2.loc[i,'Combo']=(listToString(filtered_sentence))
  return df2

def clean_2(df):
  Combo = df["Term_Type"] +" "+df["Career"] + " "+df['Program_Level']+" "+df["Study_Year"]+" "+df["Faculty_Group"]+" "+df["Program_Grouping"]+" "+df["Coop_Regular"]+" "+df["WorkTerm"]+" "+df["Attendance"]+" "+df["Visa_Status"]+" "+df["Gender"]
  Combo={'Combo':Combo}
  df2 = pd.DataFrame(Combo)
  y=len(df2)
  pos_tag2={"CC":0, "CD":0, "DT":0, "EX":0, "FW":0, "IN":0, "JJ":0, "JJR":0, "JJS":0, "LS":0, "MD":0, "NN":0, "NNS":0, "NNP":0, "NNPS":0, "PDT":0, "POS":0, "PRP":0, "PRP$":0,"RB":0,  "RBR":0,  "RBS":0,  "RP":0,  "TO":0, "UH":0, "VB":0, "VBD":0, "VBG":0, "VBN":0, "VBP":0, "VBZ":0, "WDT":0, "WP":0, "WP$":0, "WRB":0}
  for i in pos_tag2:
    df2[i]=0
  for i in range(y) : 
    text=df2.loc[i, 'Combo']
    lower_case = text.lower()
    tokens = nltk.word_tokenize(lower_case)
    tokens2= tokens
    tags = nltk.pos_tag(tokens)
    counts = Counter( tag for word,  tag in tags)
    type(counts)
    for i in counts :
        df2[i]=counts[i]  
  print(df2.columns)   
  return df2

train['Year1'] = train.Fiscal_Year.str[:4]
train['Year2'] = "20"+train.Fiscal_Year.str[5:]
train.head(5)

print(train['Year1'][0])
print(type(train['Year1'][0]))

vectorizer = TfidfVectorizer()
train_df=clean_1(train)
print(train_df)

X_counts = vectorizer.fit_transform(train_df['Combo'].values.astype('unicode'))
df=pd.DataFrame.sparse.from_spmatrix(X_counts)
df =df.join(train["Id"])
df=df.join(train["Year1"])
df=df.join(train["Year2"])
df=df.join(train["Campus_Id"])

print(df)

clean_train_df=clean_2(train)
print(clean_train_df)
result1 = pd.concat([df, clean_train_df], axis=1).reindex(df.index)
result1.drop('Combo',axis='columns', inplace=True)

print(result1)

test['Year1'] = test.Fiscal_Year.str[:4]
test['Year2'] = "20"+test.Fiscal_Year.str[5:]
test.head(5)

test_df=clean_1(test)
print(test_df)

X_counts2=vectorizer.transform(test_df['Combo'].values.astype('unicode'))
df=pd.DataFrame.sparse.from_spmatrix(X_counts2)
df =df.join(test["Id"])
df=df.join(test["Year1"])
df=df.join(test["Year2"])
df=df.join(test["Campus_Id"])

print(df)

clean_test_df=clean_2(test)
print(clean_test_df)
result2 = pd.concat([df, clean_test_df], axis=1).reindex(df.index)
result2.drop('Combo',axis='columns', inplace=True)

print(result2)

x = result1.values  
print(x)
y = y_test = train.Unique_Headcount
print(y)
x_test = result2.values
print(x_test)

"""## **Models**"""

X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.15)

#Linear Regressor
linear = LinearRegression(n_jobs=-1)
linear.fit(x, y)

#Decision Tree Regressor
dec_tree = DecisionTreeRegressor()
dec_tree.fit(x, y)

#Random Forest Regressor
rd_forest = RandomForestRegressor(n_jobs=-1)
rd_forest.fit(x,y)

"""Learned from https://www.kaggle.com/emanueleamcappella/random-forest-hyperparameters-tuning"""

#Predict RMSE for each model
learning_models = [('linear',linear), ('dec_tree',dec_tree), ('rd_forest',rd_forest)]
scoring = ['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2']

for name, model in learning_models:
  Predictions = model.predict(x)
  mse = mean_squared_error(y, Predictions, squared=False)
  print('RMSE of ' + name + ': ', mse)

# Cross-validating the models
results= []
metric= []
for name, model in learning_models:
    for score in scoring:
        scores = cross_validate(model, x, y, scoring=score, cv=10, return_train_score=True)
        results.append(scores)
print(results)

LR_RMSE_mean = np.sqrt(-results[0]['test_score'].mean())
LR_RMSE_std= results[0]['test_score'].std()
LR_MAE_mean = -results[1]['test_score'].mean()
LR_MAE_std= results[1]['test_score'].std()
LR_r2_mean = results[2]['test_score'].mean()
LR_r2_std = results[2]['test_score'].std()

RF_RMSE_mean = np.sqrt(-results[3]['test_score'].mean())
RF_RMSE_std= results[3]['test_score'].std()
RF_MAE_mean = -results[4]['test_score'].mean()
RF_MAE_std= results[4]['test_score'].std()
RF_r2_mean = results[5]['test_score'].mean()
RF_r2_std = results[5]['test_score'].std()

DT_RMSE_mean = np.sqrt(-results[6]['test_score'].mean())
DT_RMSE_std= results[6]['test_score'].std()
DT_MAE_mean = -results[7]['test_score'].mean()
DT_MAE_std= results[7]['test_score'].std()
DT_r2_mean = results[8]['test_score'].mean()
DT_r2_std = results[8]['test_score'].std()


modelDF = pd.DataFrame({
    'Model'       : ['Linear Regression', 'Random Forest', 'Decision Trees'],
    'RMSE_mean'    : [LR_RMSE_mean, RF_RMSE_mean, DT_RMSE_mean],
    'RMSE_std'    : [LR_RMSE_std, RF_RMSE_std, DT_RMSE_std],
    'MAE_mean'   : [LR_MAE_mean, RF_MAE_mean, DT_MAE_mean],
    'MAE_std'   : [LR_MAE_std, RF_MAE_std, DT_MAE_std],
    'r2_mean'      : [LR_r2_mean, RF_r2_mean, DT_r2_mean],
    'r2_std'      : [LR_r2_std, RF_r2_std, DT_r2_std],
    }, columns = ['Model', 'RMSE_mean', 'RMSE_std', 'MAE_mean', 'MAE_std', 'r2_mean', 'r2_std'])

modelDF.sort_values(by='r2_mean', ascending=False)

sns.factorplot(x= 'Model', y= 'RMSE_mean', data= modelDF, kind='bar', legend='True')

"""## **Random Forest**

Tuning Hyperparameters
"""

param_grid = [{'n_estimators': [500, 1000], 'max_features': [5, 10], 'max_depth': [10, 50, None], 'bootstrap': [True, False]}]

grid_search_rd_forest = GridSearchCV(forest, param_grid, cv=10, scoring='neg_mean_squared_error')
grid_search_rd_forest.fit(x, y)

cvres = grid_search_rd_forest.cv_results_
for mean_score, params in zip(cvres["mean_test_score"], cvres["params"]):
    print(np.sqrt(-mean_score), params)

grid_search_rd_forest.best_estimator_

grid_rmse = mean_squared_error(y_train, grid_best, squared=False)
print(grid_rmse)

"""## **Other**"""

regr = RandomForestRegressor(n_estimators= 1000, random_state=100, max_features=0.4, min_samples_leaf=3, oob_score=True)
regr.fit(x, y)
y_pred = regr.predict(x_test)
print(y_pred)
res = []
for i in range(test.shape[0]):
  res.append((test['Id'][i],y_pred[i]))
print(res)
DF = pd.DataFrame(res) 
DF.to_csv("SheHacks_Submission.csv")